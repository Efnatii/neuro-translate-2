{
  "testMode": "real",
  "logs": {
    "ok": true,
    "seq": 266,
    "logs": [
      {
        "ts": 1772056677027,
        "level": "info",
        "tag": "ai.choose",
        "message": "model selected",
        "meta": {
          "source": "ai",
          "tabId": 849091790,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 67
      },
      {
        "ts": 1772056677877,
        "level": "warn",
        "tag": "ai.request",
        "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "ping",
          "modelSpec": "o4-mini:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 68
      },
      {
        "ts": 1772056678137,
        "level": "warn",
        "tag": "ai.request",
        "message": "Request aborted: ABORTED_BY_SIGNAL",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "ping",
          "modelSpec": "gpt-5:standard",
          "status": null,
          "latencyMs": null
        },
        "seq": 69
      },
      {
        "ts": 1772056678158,
        "level": "error",
        "tag": "bg.error",
        "message": "Quick bench sample failed",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "quick",
          "modelSpec": "gpt-5:standard",
          "status": null,
          "latencyMs": null
        },
        "seq": 70
      },
      {
        "ts": 1772056678159,
        "level": "info",
        "tag": "bg.error",
        "message": "Quick prebench finished",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "quick",
          "modelSpec": null,
          "status": 3,
          "latencyMs": null
        },
        "seq": 71
      },
      {
        "ts": 1772056678186,
        "level": "info",
        "tag": "ai.choose",
        "message": "model selected",
        "meta": {
          "source": "ai",
          "tabId": 849091790,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 72
      },
      {
        "ts": 1772056685686,
        "level": "info",
        "tag": "ai.response",
        "message": "ok",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "request",
          "modelSpec": "gpt-5-mini:standard",
          "status": 200,
          "latencyMs": 7486
        },
        "seq": 73
      },
      {
        "ts": 1772056685725,
        "level": "info",
        "tag": "ai.response",
        "message": "ok",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "request",
          "modelSpec": "gpt-5-mini:standard",
          "status": 200,
          "latencyMs": 8670
        },
        "seq": 74
      },
      {
        "ts": 1772056685727,
        "level": "info",
        "tag": "ai.response",
        "message": "response metrics",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": "gpt-5-mini:standard",
          "status": 200,
          "latencyMs": 7500
        },
        "seq": 75
      },
      {
        "ts": 1772056685732,
        "level": "info",
        "tag": "ai.response",
        "message": "response metrics",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": "gpt-5-mini:standard",
          "status": 200,
          "latencyMs": 8693
        },
        "seq": 76
      },
      {
        "ts": 1772056685741,
        "level": "info",
        "tag": "ai.response",
        "message": "LLM ok",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": 200,
          "latencyMs": 9166
        },
        "seq": 77
      },
      {
        "ts": 1772056685742,
        "level": "info",
        "tag": "ai.response",
        "message": "LLM ok",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": 200,
          "latencyMs": 8822
        },
        "seq": 78
      },
      {
        "ts": 1772056686698,
        "level": "warn",
        "tag": "ai.request",
        "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "ping",
          "modelSpec": "gpt-5:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 79
      },
      {
        "ts": 1772056690243,
        "level": "warn",
        "tag": "ai.request",
        "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "ping",
          "modelSpec": "o4-mini:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 80
      },
      {
        "ts": 1772056690468,
        "level": "error",
        "tag": "bg.error",
        "message": "Bench failed",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": "o4-mini:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 81
      },
      {
        "ts": 1772056690471,
        "level": "warn",
        "tag": "ai.request",
        "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "ping",
          "modelSpec": "gpt-4.1-mini:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 82
      },
      {
        "ts": 1772056690820,
        "level": "warn",
        "tag": "ai.request",
        "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "ping",
          "modelSpec": "gpt-4o-mini:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 83
      },
      {
        "ts": 1772056691056,
        "level": "error",
        "tag": "bg.error",
        "message": "Bench failed",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": "gpt-4o-mini:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 84
      },
      {
        "ts": 1772056692734,
        "level": "warn",
        "tag": "ai.request",
        "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "ping",
          "modelSpec": "gpt-5:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 85
      },
      {
        "ts": 1772056692747,
        "level": "error",
        "tag": "bg.error",
        "message": "Bench failed",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": "gpt-5:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 86
      },
      {
        "ts": 1772056692766,
        "level": "info",
        "tag": "bg.error",
        "message": "Quick prebench started",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "quick",
          "modelSpec": null,
          "status": 4,
          "latencyMs": null
        },
        "seq": 87
      },
      {
        "ts": 1772056692768,
        "level": "info",
        "tag": "bg.error",
        "message": "Quick prebench started",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "quick",
          "modelSpec": null,
          "status": 4,
          "latencyMs": null
        },
        "seq": 88
      },
      {
        "ts": 1772056692786,
        "level": "info",
        "tag": "bg.error",
        "message": "Quick prebench finished",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "quick",
          "modelSpec": null,
          "status": 4,
          "latencyMs": null
        },
        "seq": 89
      },
      {
        "ts": 1772056692788,
        "level": "info",
        "tag": "bg.error",
        "message": "Quick prebench finished",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "quick",
          "modelSpec": null,
          "status": 4,
          "latencyMs": null
        },
        "seq": 90
      },
      {
        "ts": 1772056692798,
        "level": "info",
        "tag": "bg.error",
        "message": "Bench started",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": null,
          "status": 1,
          "latencyMs": null
        },
        "seq": 91
      },
      {
        "ts": 1772056692798,
        "level": "info",
        "tag": "bg.error",
        "message": "Bench started",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": null,
          "status": 1,
          "latencyMs": null
        },
        "seq": 92
      },
      {
        "ts": 1772056692803,
        "level": "info",
        "tag": "ai.choose",
        "message": "model selected",
        "meta": {
          "source": "ai",
          "tabId": 849091790,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 93
      },
      {
        "ts": 1772056692813,
        "level": "info",
        "tag": "ai.choose",
        "message": "model selected",
        "meta": {
          "source": "ai",
          "tabId": 849091790,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 94
      },
      {
        "ts": 1772056696889,
        "level": "info",
        "tag": "ai.response",
        "message": "ok",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "request",
          "modelSpec": "gpt-5-mini:standard",
          "status": 200,
          "latencyMs": 4065
        },
        "seq": 95
      },
      {
        "ts": 1772056696928,
        "level": "info",
        "tag": "ai.response",
        "message": "response metrics",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": "gpt-5-mini:standard",
          "status": 200,
          "latencyMs": 4085
        },
        "seq": 96
      },
      {
        "ts": 1772056696936,
        "level": "warn",
        "tag": "ai.request",
        "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "ping",
          "modelSpec": "o4-mini:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 97
      },
      {
        "ts": 1772056696967,
        "level": "warn",
        "tag": "ai.request",
        "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "ping",
          "modelSpec": "gpt-4.1-mini:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 98
      },
      {
        "ts": 1772056697023,
        "level": "info",
        "tag": "ai.response",
        "message": "LLM ok",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": 200,
          "latencyMs": 4325
        },
        "seq": 99
      },
      {
        "ts": 1772056697067,
        "level": "warn",
        "tag": "ai.request",
        "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "ping",
          "modelSpec": "gpt-4.1-mini:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 100
      },
      {
        "ts": 1772056697168,
        "level": "info",
        "tag": "ai.response",
        "message": "ok",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "request",
          "modelSpec": "gpt-5-mini:standard",
          "status": 200,
          "latencyMs": 4296
        },
        "seq": 101
      },
      {
        "ts": 1772056697170,
        "level": "error",
        "tag": "bg.error",
        "message": "Bench failed",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": "gpt-4.1-mini:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 102
      },
      {
        "ts": 1772056697215,
        "level": "info",
        "tag": "ai.response",
        "message": "response metrics",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": "gpt-5-mini:standard",
          "status": 200,
          "latencyMs": 4355
        },
        "seq": 103
      },
      {
        "ts": 1772056697223,
        "level": "warn",
        "tag": "ai.request",
        "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "ping",
          "modelSpec": "o3:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 104
      },
      {
        "ts": 1772056697270,
        "level": "info",
        "tag": "ai.response",
        "message": "LLM ok",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": 200,
          "latencyMs": 4566
        },
        "seq": 105
      },
      {
        "ts": 1772056697767,
        "level": "warn",
        "tag": "ai.request",
        "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "ping",
          "modelSpec": "gpt-5:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 106
      },
      {
        "ts": 1772056698088,
        "level": "warn",
        "tag": "ai.request",
        "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "ping",
          "modelSpec": "o3:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 107
      },
      {
        "ts": 1772056700667,
        "level": "warn",
        "tag": "ai.request",
        "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "ping",
          "modelSpec": "gpt-4.1-mini:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 108
      },
      {
        "ts": 1772056701046,
        "level": "error",
        "tag": "bg.error",
        "message": "Bench failed",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": "gpt-4.1-mini:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 109
      },
      {
        "ts": 1772056701054,
        "level": "warn",
        "tag": "ai.request",
        "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "ping",
          "modelSpec": "o4-mini:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 110
      },
      {
        "ts": 1772056701188,
        "level": "error",
        "tag": "bg.error",
        "message": "Bench failed",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": "o4-mini:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 111
      },
      {
        "ts": 1772056701556,
        "level": "warn",
        "tag": "ai.request",
        "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "ping",
          "modelSpec": "o3:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 112
      },
      {
        "ts": 1772056701742,
        "level": "error",
        "tag": "bg.error",
        "message": "Bench failed",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": "o3:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 113
      },
      {
        "ts": 1772056701944,
        "level": "info",
        "tag": "bg.error",
        "message": "Bench finished",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": null,
          "status": 1,
          "latencyMs": null
        },
        "seq": 114
      },
      {
        "ts": 1772056701960,
        "level": "warn",
        "tag": "ai.request",
        "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "ping",
          "modelSpec": "o3:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 115
      },
      {
        "ts": 1772056701975,
        "level": "warn",
        "tag": "ai.request",
        "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "ping",
          "modelSpec": "gpt-5:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 116
      },
      {
        "ts": 1772056702056,
        "level": "error",
        "tag": "bg.error",
        "message": "Bench failed",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": "gpt-5:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 117
      },
      {
        "ts": 1772056702074,
        "level": "warn",
        "tag": "ai.request",
        "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "ping",
          "modelSpec": "o3:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 118
      },
      {
        "ts": 1772056702111,
        "level": "error",
        "tag": "bg.error",
        "message": "Bench failed",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": "o3:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 119
      },
      {
        "ts": 1772056702173,
        "level": "info",
        "tag": "bg.error",
        "message": "Bench finished",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": null,
          "status": 1,
          "latencyMs": null
        },
        "seq": 120
      },
      {
        "ts": 1772056702430,
        "level": "info",
        "tag": "bg.error",
        "message": "Quick prebench started",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "quick",
          "modelSpec": null,
          "status": 4,
          "latencyMs": null
        },
        "seq": 121
      },
      {
        "ts": 1772056702457,
        "level": "info",
        "tag": "bg.error",
        "message": "Quick prebench finished",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "quick",
          "modelSpec": null,
          "status": 4,
          "latencyMs": null
        },
        "seq": 122
      },
      {
        "ts": 1772056702465,
        "level": "info",
        "tag": "bg.error",
        "message": "Quick prebench started",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "quick",
          "modelSpec": null,
          "status": 4,
          "latencyMs": null
        },
        "seq": 123
      },
      {
        "ts": 1772056702494,
        "level": "info",
        "tag": "bg.error",
        "message": "Bench started",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 124
      },
      {
        "ts": 1772056702532,
        "level": "info",
        "tag": "bg.error",
        "message": "Bench finished",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 125
      },
      {
        "ts": 1772056702540,
        "level": "info",
        "tag": "ai.choose",
        "message": "model selected",
        "meta": {
          "source": "ai",
          "tabId": 849091790,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 126
      },
      {
        "ts": 1772056702566,
        "level": "info",
        "tag": "bg.error",
        "message": "Quick prebench finished",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "quick",
          "modelSpec": null,
          "status": 4,
          "latencyMs": null
        },
        "seq": 127
      },
      {
        "ts": 1772056702602,
        "level": "info",
        "tag": "bg.error",
        "message": "Bench started",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 128
      },
      {
        "ts": 1772056702605,
        "level": "info",
        "tag": "bg.error",
        "message": "Bench finished",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 129
      },
      {
        "ts": 1772056702616,
        "level": "info",
        "tag": "ai.choose",
        "message": "model selected",
        "meta": {
          "source": "ai",
          "tabId": 849091790,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 130
      },
      {
        "ts": 1772056705199,
        "level": "info",
        "tag": "ai.response",
        "message": "ok",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "request",
          "modelSpec": "gpt-5-mini:standard",
          "status": 200,
          "latencyMs": 2601
        },
        "seq": 131
      },
      {
        "ts": 1772056705330,
        "level": "warn",
        "tag": "ai.request",
        "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "ping",
          "modelSpec": "gpt-5:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 132
      },
      {
        "ts": 1772056705338,
        "level": "info",
        "tag": "ai.response",
        "message": "response metrics",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": "gpt-5-mini:standard",
          "status": 200,
          "latencyMs": 2665
        },
        "seq": 133
      },
      {
        "ts": 1772056705360,
        "level": "warn",
        "tag": "ai.request",
        "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "ping",
          "modelSpec": "gpt-4.1-mini:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 134
      },
      {
        "ts": 1772056705364,
        "level": "info",
        "tag": "ai.response",
        "message": "LLM ok",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": 200,
          "latencyMs": 3305
        },
        "seq": 135
      },
      {
        "ts": 1772056706087,
        "level": "info",
        "tag": "ai.response",
        "message": "ok",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "request",
          "modelSpec": "gpt-5-mini:standard",
          "status": 200,
          "latencyMs": 3457
        },
        "seq": 136
      },
      {
        "ts": 1772056706233,
        "level": "info",
        "tag": "ai.response",
        "message": "response metrics",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": "gpt-5-mini:standard",
          "status": 200,
          "latencyMs": 3475
        },
        "seq": 137
      },
      {
        "ts": 1772056706266,
        "level": "warn",
        "tag": "ai.request",
        "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "ping",
          "modelSpec": "o3:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 138
      },
      {
        "ts": 1772056706321,
        "level": "info",
        "tag": "ai.response",
        "message": "LLM ok",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": 200,
          "latencyMs": 4148
        },
        "seq": 139
      },
      {
        "ts": 1772056706336,
        "level": "warn",
        "tag": "ai.request",
        "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "ping",
          "modelSpec": "o3:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 140
      },
      {
        "ts": 1772056706425,
        "level": "error",
        "tag": "bg.error",
        "message": "Bench failed",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": "o3:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 141
      },
      {
        "ts": 1772056706625,
        "level": "info",
        "tag": "bg.error",
        "message": "Bench finished",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": null,
          "status": 2,
          "latencyMs": null
        },
        "seq": 142
      },
      {
        "ts": 1772056708511,
        "level": "warn",
        "tag": "ai.request",
        "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "ping",
          "modelSpec": "gpt-5:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 143
      },
      {
        "ts": 1772056708845,
        "level": "error",
        "tag": "bg.error",
        "message": "Bench failed",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": "gpt-5:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 144
      },
      {
        "ts": 1772056709399,
        "level": "warn",
        "tag": "ai.request",
        "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "ping",
          "modelSpec": "gpt-4.1-mini:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 145
      },
      {
        "ts": 1772056709715,
        "level": "error",
        "tag": "bg.error",
        "message": "Bench failed",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": "gpt-4.1-mini:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 146
      },
      {
        "ts": 1772056709875,
        "level": "warn",
        "tag": "ai.request",
        "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "ping",
          "modelSpec": "o3:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 147
      },
      {
        "ts": 1772056709968,
        "level": "error",
        "tag": "bg.error",
        "message": "Bench failed",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": "o3:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 148
      },
      {
        "ts": 1772056710097,
        "level": "info",
        "tag": "bg.error",
        "message": "Bench finished",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": null,
          "status": 3,
          "latencyMs": null
        },
        "seq": 149
      },
      {
        "ts": 1772056710905,
        "level": "info",
        "tag": "bg.error",
        "message": "Quick prebench started",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "quick",
          "modelSpec": null,
          "status": 4,
          "latencyMs": null
        },
        "seq": 150
      },
      {
        "ts": 1772056711018,
        "level": "info",
        "tag": "bg.error",
        "message": "Quick prebench finished",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "quick",
          "modelSpec": null,
          "status": 4,
          "latencyMs": null
        },
        "seq": 151
      },
      {
        "ts": 1772056711087,
        "level": "info",
        "tag": "bg.error",
        "message": "Bench started",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 152
      },
      {
        "ts": 1772056711091,
        "level": "info",
        "tag": "ai.choose",
        "message": "model selected",
        "meta": {
          "source": "ai",
          "tabId": 849091790,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 153
      },
      {
        "ts": 1772056711111,
        "level": "info",
        "tag": "bg.error",
        "message": "Bench finished",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 154
      },
      {
        "ts": 1772056711187,
        "level": "warn",
        "tag": "ai.request",
        "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "ping",
          "modelSpec": "gpt-4.1-mini:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 155
      },
      {
        "ts": 1772056711197,
        "level": "info",
        "tag": "bg.error",
        "message": "Quick prebench started",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "quick",
          "modelSpec": null,
          "status": 4,
          "latencyMs": null
        },
        "seq": 156
      },
      {
        "ts": 1772056711224,
        "level": "info",
        "tag": "bg.error",
        "message": "Quick prebench finished",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "quick",
          "modelSpec": null,
          "status": 4,
          "latencyMs": null
        },
        "seq": 157
      },
      {
        "ts": 1772056711397,
        "level": "info",
        "tag": "bg.error",
        "message": "Bench started",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 158
      },
      {
        "ts": 1772056711400,
        "level": "info",
        "tag": "ai.choose",
        "message": "model selected",
        "meta": {
          "source": "ai",
          "tabId": 849091790,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 159
      },
      {
        "ts": 1772056711452,
        "level": "info",
        "tag": "bg.error",
        "message": "Bench finished",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 160
      },
      {
        "ts": 1772056714917,
        "level": "info",
        "tag": "ai.response",
        "message": "ok",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "request",
          "modelSpec": "gpt-5-mini:standard",
          "status": 200,
          "latencyMs": 3429
        },
        "seq": 161
      },
      {
        "ts": 1772056714962,
        "level": "info",
        "tag": "ai.response",
        "message": "response metrics",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": "gpt-5-mini:standard",
          "status": 200,
          "latencyMs": 3516
        },
        "seq": 162
      },
      {
        "ts": 1772056714964,
        "level": "info",
        "tag": "ai.response",
        "message": "ok",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "request",
          "modelSpec": "gpt-5-mini:standard",
          "status": 200,
          "latencyMs": 3840
        },
        "seq": 163
      },
      {
        "ts": 1772056714978,
        "level": "info",
        "tag": "ai.response",
        "message": "response metrics",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": "gpt-5-mini:standard",
          "status": 200,
          "latencyMs": 3872
        },
        "seq": 164
      },
      {
        "ts": 1772056714981,
        "level": "warn",
        "tag": "ai.request",
        "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "ping",
          "modelSpec": "o3:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 165
      },
      {
        "ts": 1772056714985,
        "level": "info",
        "tag": "ai.response",
        "message": "LLM ok",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": 200,
          "latencyMs": 3967
        },
        "seq": 166
      },
      {
        "ts": 1772056715003,
        "level": "info",
        "tag": "ai.response",
        "message": "LLM ok",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": 200,
          "latencyMs": 4588
        },
        "seq": 167
      },
      {
        "ts": 1772056715903,
        "level": "warn",
        "tag": "ai.request",
        "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "ping",
          "modelSpec": "gpt-4.1-mini:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 168
      },
      {
        "ts": 1772056716013,
        "level": "error",
        "tag": "bg.error",
        "message": "Bench failed",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": "gpt-4.1-mini:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 169
      },
      {
        "ts": 1772056717840,
        "level": "warn",
        "tag": "ai.request",
        "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "ping",
          "modelSpec": "o3:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 170
      },
      {
        "ts": 1772056718121,
        "level": "error",
        "tag": "bg.error",
        "message": "Bench failed",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": "o3:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 171
      },
      {
        "ts": 1772056718403,
        "level": "info",
        "tag": "bg.error",
        "message": "Bench finished",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": null,
          "status": 5,
          "latencyMs": null
        },
        "seq": 172
      },
      {
        "ts": 1772056719350,
        "level": "warn",
        "tag": "ai.request",
        "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "ping",
          "modelSpec": "o3:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 173
      },
      {
        "ts": 1772056719666,
        "level": "info",
        "tag": "bg.error",
        "message": "Quick prebench started",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "quick",
          "modelSpec": null,
          "status": 4,
          "latencyMs": null
        },
        "seq": 174
      },
      {
        "ts": 1772056719677,
        "level": "info",
        "tag": "bg.error",
        "message": "Quick prebench started",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "quick",
          "modelSpec": null,
          "status": 4,
          "latencyMs": null
        },
        "seq": 175
      },
      {
        "ts": 1772056719688,
        "level": "info",
        "tag": "bg.error",
        "message": "Quick prebench finished",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "quick",
          "modelSpec": null,
          "status": 4,
          "latencyMs": null
        },
        "seq": 176
      },
      {
        "ts": 1772056719716,
        "level": "info",
        "tag": "bg.error",
        "message": "Bench started",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 177
      },
      {
        "ts": 1772056719740,
        "level": "info",
        "tag": "bg.error",
        "message": "Quick prebench finished",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "quick",
          "modelSpec": null,
          "status": 4,
          "latencyMs": null
        },
        "seq": 178
      },
      {
        "ts": 1772056719742,
        "level": "info",
        "tag": "bg.error",
        "message": "Bench finished",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 179
      },
      {
        "ts": 1772056719744,
        "level": "info",
        "tag": "bg.error",
        "message": "Bench started",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 180
      },
      {
        "ts": 1772056719747,
        "level": "info",
        "tag": "ai.choose",
        "message": "model selected",
        "meta": {
          "source": "ai",
          "tabId": 849091790,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 181
      },
      {
        "ts": 1772056719791,
        "level": "info",
        "tag": "bg.error",
        "message": "Bench finished",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 182
      },
      {
        "ts": 1772056719812,
        "level": "info",
        "tag": "ai.choose",
        "message": "model selected",
        "meta": {
          "source": "ai",
          "tabId": 849091790,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 183
      },
      {
        "ts": 1772056725682,
        "level": "info",
        "tag": "ai.response",
        "message": "ok",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "request",
          "modelSpec": "gpt-5-mini:standard",
          "status": 200,
          "latencyMs": 5870
        },
        "seq": 184
      },
      {
        "ts": 1772056725751,
        "level": "warn",
        "tag": "ai.request",
        "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "ping",
          "modelSpec": "o3:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 185
      },
      {
        "ts": 1772056725753,
        "level": "info",
        "tag": "ai.response",
        "message": "response metrics",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": "gpt-5-mini:standard",
          "status": 200,
          "latencyMs": 5934
        },
        "seq": 186
      },
      {
        "ts": 1772056725755,
        "level": "info",
        "tag": "ai.response",
        "message": "ok",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "request",
          "modelSpec": "gpt-5-mini:standard",
          "status": 200,
          "latencyMs": 5929
        },
        "seq": 187
      },
      {
        "ts": 1772056725791,
        "level": "info",
        "tag": "ai.response",
        "message": "response metrics",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": "gpt-5-mini:standard",
          "status": 200,
          "latencyMs": 5940
        },
        "seq": 188
      },
      {
        "ts": 1772056725815,
        "level": "error",
        "tag": "bg.error",
        "message": "Bench failed",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": "o3:standard",
          "status": 400,
          "latencyMs": null
        },
        "seq": 189
      },
      {
        "ts": 1772056725819,
        "level": "info",
        "tag": "ai.response",
        "message": "LLM ok",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": 200,
          "latencyMs": 6347
        },
        "seq": 190
      },
      {
        "ts": 1772056725850,
        "level": "info",
        "tag": "ai.response",
        "message": "LLM ok",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": 200,
          "latencyMs": 6375
        },
        "seq": 191
      },
      {
        "ts": 1772056725879,
        "level": "info",
        "tag": "bg.error",
        "message": "Bench finished",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": null,
          "status": 6,
          "latencyMs": null
        },
        "seq": 192
      },
      {
        "ts": 1772056728190,
        "level": "info",
        "tag": "bg.error",
        "message": "Quick prebench started",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "quick",
          "modelSpec": null,
          "status": 4,
          "latencyMs": null
        },
        "seq": 193
      },
      {
        "ts": 1772056728193,
        "level": "info",
        "tag": "bg.error",
        "message": "Quick prebench started",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "quick",
          "modelSpec": null,
          "status": 4,
          "latencyMs": null
        },
        "seq": 194
      },
      {
        "ts": 1772056728203,
        "level": "info",
        "tag": "bg.error",
        "message": "Quick prebench finished",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "quick",
          "modelSpec": null,
          "status": 4,
          "latencyMs": null
        },
        "seq": 195
      },
      {
        "ts": 1772056728212,
        "level": "info",
        "tag": "bg.error",
        "message": "Quick prebench finished",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "quick",
          "modelSpec": null,
          "status": 4,
          "latencyMs": null
        },
        "seq": 196
      },
      {
        "ts": 1772056728214,
        "level": "info",
        "tag": "bg.error",
        "message": "Bench started",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 197
      },
      {
        "ts": 1772056728214,
        "level": "info",
        "tag": "bg.error",
        "message": "Bench started",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 198
      },
      {
        "ts": 1772056728222,
        "level": "info",
        "tag": "ai.choose",
        "message": "model selected",
        "meta": {
          "source": "ai",
          "tabId": 849091790,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 199
      },
      {
        "ts": 1772056728224,
        "level": "info",
        "tag": "bg.error",
        "message": "Bench finished",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 200
      },
      {
        "ts": 1772056728224,
        "level": "info",
        "tag": "bg.error",
        "message": "Bench finished",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 201
      },
      {
        "ts": 1772056728246,
        "level": "info",
        "tag": "ai.choose",
        "message": "model selected",
        "meta": {
          "source": "ai",
          "tabId": 849091790,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 202
      },
      {
        "ts": 1772056730534,
        "level": "info",
        "tag": "ai.response",
        "message": "ok",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "request",
          "modelSpec": "gpt-5:standard",
          "status": 200,
          "latencyMs": 2285
        },
        "seq": 203
      },
      {
        "ts": 1772056730536,
        "level": "info",
        "tag": "ai.response",
        "message": "ok",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "request",
          "modelSpec": "gpt-5:standard",
          "status": 200,
          "latencyMs": 2279
        },
        "seq": 204
      },
      {
        "ts": 1772056730545,
        "level": "info",
        "tag": "ai.response",
        "message": "response metrics",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": "gpt-5:standard",
          "status": 200,
          "latencyMs": 2311
        },
        "seq": 205
      },
      {
        "ts": 1772056730547,
        "level": "info",
        "tag": "ai.response",
        "message": "response metrics",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": "gpt-5:standard",
          "status": 200,
          "latencyMs": 2289
        },
        "seq": 206
      },
      {
        "ts": 1772056730556,
        "level": "info",
        "tag": "ai.response",
        "message": "LLM ok",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": 200,
          "latencyMs": 2377
        },
        "seq": 207
      },
      {
        "ts": 1772056730558,
        "level": "info",
        "tag": "ai.response",
        "message": "LLM ok",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": 200,
          "latencyMs": 2377
        },
        "seq": 208
      },
      {
        "ts": 1772056736742,
        "level": "info",
        "tag": "bg.start",
        "message": " wake alarm",
        "meta": {
          "source": "bg",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 209
      },
      {
        "ts": 1772056737880,
        "level": "info",
        "tag": "bg.start",
        "message": "Scheduler tick ",
        "meta": {
          "source": "bg",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 210
      },
      {
        "ts": 1772056737888,
        "level": "info",
        "tag": "bg.start",
        "message": " wake alarm",
        "meta": {
          "source": "bg",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 211
      },
      {
        "ts": 1772056739343,
        "level": "info",
        "tag": "bg.start",
        "message": " wake alarm",
        "meta": {
          "source": "bg",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 212
      },
      {
        "ts": 1772056739606,
        "level": "info",
        "tag": "bg.start",
        "message": "Scheduler tick ",
        "meta": {
          "source": "bg",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 213
      },
      {
        "ts": 1772056740056,
        "level": "info",
        "tag": "bg.start",
        "message": " wake alarm",
        "meta": {
          "source": "bg",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 214
      },
      {
        "ts": 1772056740439,
        "level": "info",
        "tag": "bg.start",
        "message": "Scheduler tick ",
        "meta": {
          "source": "bg",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 215
      },
      {
        "ts": 1772056742079,
        "level": "info",
        "tag": "bg.error",
        "message": "Quick prebench started",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "quick",
          "modelSpec": null,
          "status": 4,
          "latencyMs": null
        },
        "seq": 216
      },
      {
        "ts": 1772056742091,
        "level": "info",
        "tag": "bg.start",
        "message": "Scheduler tick ",
        "meta": {
          "source": "bg",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 217
      },
      {
        "ts": 1772056742095,
        "level": "info",
        "tag": "bg.start",
        "message": " wake alarm",
        "meta": {
          "source": "bg",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 218
      },
      {
        "ts": 1772056742104,
        "level": "info",
        "tag": "bg.error",
        "message": "Bench started",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 219
      },
      {
        "ts": 1772056742104,
        "level": "info",
        "tag": "bg.error",
        "message": "Quick prebench finished",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "quick",
          "modelSpec": null,
          "status": 4,
          "latencyMs": null
        },
        "seq": 220
      },
      {
        "ts": 1772056742115,
        "level": "info",
        "tag": "bg.error",
        "message": "Bench finished",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 221
      },
      {
        "ts": 1772056742135,
        "level": "info",
        "tag": "ai.choose",
        "message": "model selected",
        "meta": {
          "source": "ai",
          "tabId": 849091790,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 222
      },
      {
        "ts": 1772056744386,
        "level": "info",
        "tag": "bg.start",
        "message": "Scheduler tick ",
        "meta": {
          "source": "bg",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 223
      },
      {
        "ts": 1772056744391,
        "level": "info",
        "tag": "bg.start",
        "message": " wake alarm",
        "meta": {
          "source": "bg",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 224
      },
      {
        "ts": 1772056745905,
        "level": "info",
        "tag": "ai.response",
        "message": "ok",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "request",
          "modelSpec": "gpt-5-mini:standard",
          "status": 200,
          "latencyMs": 3720
        },
        "seq": 225
      },
      {
        "ts": 1772056745984,
        "level": "info",
        "tag": "ai.response",
        "message": "response metrics",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": "gpt-5-mini:standard",
          "status": 200,
          "latencyMs": 3769
        },
        "seq": 226
      },
      {
        "ts": 1772056745995,
        "level": "info",
        "tag": "ai.response",
        "message": "LLM ok",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": 200,
          "latencyMs": 4233
        },
        "seq": 227
      },
      {
        "ts": 1772056747582,
        "level": "info",
        "tag": "bg.start",
        "message": "Scheduler tick ",
        "meta": {
          "source": "bg",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 228
      },
      {
        "ts": 1772056747589,
        "level": "info",
        "tag": "bg.start",
        "message": " wake alarm",
        "meta": {
          "source": "bg",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 229
      },
      {
        "ts": 1772056750680,
        "level": "info",
        "tag": "bg.start",
        "message": "Scheduler tick ",
        "meta": {
          "source": "bg",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 230
      },
      {
        "ts": 1772056750688,
        "level": "info",
        "tag": "bg.start",
        "message": " wake alarm",
        "meta": {
          "source": "bg",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 231
      },
      {
        "ts": 1772056751847,
        "level": "info",
        "tag": "bg.error",
        "message": "Quick prebench started",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "quick",
          "modelSpec": null,
          "status": 4,
          "latencyMs": null
        },
        "seq": 232
      },
      {
        "ts": 1772056751944,
        "level": "info",
        "tag": "bg.error",
        "message": "Quick prebench finished",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "quick",
          "modelSpec": null,
          "status": 4,
          "latencyMs": null
        },
        "seq": 233
      },
      {
        "ts": 1772056751958,
        "level": "info",
        "tag": "bg.error",
        "message": "Bench started",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 234
      },
      {
        "ts": 1772056751962,
        "level": "info",
        "tag": "bg.error",
        "message": "Bench finished",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 235
      },
      {
        "ts": 1772056751976,
        "level": "info",
        "tag": "ai.choose",
        "message": "model selected",
        "meta": {
          "source": "ai",
          "tabId": 849091790,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 236
      },
      {
        "ts": 1772056752712,
        "level": "info",
        "tag": "bg.start",
        "message": "Scheduler tick ",
        "meta": {
          "source": "bg",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 237
      },
      {
        "ts": 1772056752717,
        "level": "info",
        "tag": "bg.start",
        "message": " wake alarm",
        "meta": {
          "source": "bg",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 238
      },
      {
        "ts": 1772056754799,
        "level": "info",
        "tag": "ai.response",
        "message": "ok",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "request",
          "modelSpec": "gpt-5-mini:standard",
          "status": 200,
          "latencyMs": 2809
        },
        "seq": 239
      },
      {
        "ts": 1772056754846,
        "level": "info",
        "tag": "ai.response",
        "message": "response metrics",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": "gpt-5-mini:standard",
          "status": 200,
          "latencyMs": 2823
        },
        "seq": 240
      },
      {
        "ts": 1772056754919,
        "level": "info",
        "tag": "ai.response",
        "message": "LLM ok",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": 200,
          "latencyMs": 3555
        },
        "seq": 241
      },
      {
        "ts": 1772056755437,
        "level": "info",
        "tag": "bg.start",
        "message": "Scheduler tick ",
        "meta": {
          "source": "bg",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 242
      },
      {
        "ts": 1772056755448,
        "level": "info",
        "tag": "bg.start",
        "message": " wake alarm",
        "meta": {
          "source": "bg",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 243
      },
      {
        "ts": 1772056761002,
        "level": "info",
        "tag": "bg.start",
        "message": "Scheduler tick ",
        "meta": {
          "source": "bg",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 244
      },
      {
        "ts": 1772056761006,
        "level": "info",
        "tag": "bg.start",
        "message": " wake alarm",
        "meta": {
          "source": "bg",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 245
      },
      {
        "ts": 1772056763622,
        "level": "info",
        "tag": "bg.error",
        "message": "Quick prebench started",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "quick",
          "modelSpec": null,
          "status": 4,
          "latencyMs": null
        },
        "seq": 246
      },
      {
        "ts": 1772056763635,
        "level": "info",
        "tag": "bg.error",
        "message": "Quick prebench finished",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "quick",
          "modelSpec": null,
          "status": 4,
          "latencyMs": null
        },
        "seq": 247
      },
      {
        "ts": 1772056763647,
        "level": "info",
        "tag": "bg.start",
        "message": "Scheduler tick ",
        "meta": {
          "source": "bg",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 248
      },
      {
        "ts": 1772056763650,
        "level": "info",
        "tag": "bg.error",
        "message": "Bench started",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 249
      },
      {
        "ts": 1772056763652,
        "level": "info",
        "tag": "bg.start",
        "message": " wake alarm",
        "meta": {
          "source": "bg",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 250
      },
      {
        "ts": 1772056763661,
        "level": "info",
        "tag": "bg.error",
        "message": "Bench finished",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 251
      },
      {
        "ts": 1772056763670,
        "level": "info",
        "tag": "ai.choose",
        "message": "model selected",
        "meta": {
          "source": "ai",
          "tabId": 849091790,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 252
      },
      {
        "ts": 1772056765647,
        "level": "info",
        "tag": "bg.start",
        "message": "Scheduler tick ",
        "meta": {
          "source": "bg",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 253
      },
      {
        "ts": 1772056765651,
        "level": "info",
        "tag": "bg.start",
        "message": " wake alarm",
        "meta": {
          "source": "bg",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 254
      },
      {
        "ts": 1772056767075,
        "level": "info",
        "tag": "ai.response",
        "message": "ok",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": "request",
          "modelSpec": "gpt-5-mini:standard",
          "status": 200,
          "latencyMs": 3383
        },
        "seq": 255
      },
      {
        "ts": 1772056767086,
        "level": "info",
        "tag": "ai.response",
        "message": "response metrics",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": "gpt-5-mini:standard",
          "status": 200,
          "latencyMs": 3404
        },
        "seq": 256
      },
      {
        "ts": 1772056767098,
        "level": "info",
        "tag": "ai.response",
        "message": "LLM ok",
        "meta": {
          "source": "ai",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": 200,
          "latencyMs": 3726
        },
        "seq": 257
      },
      {
        "ts": 1772056768104,
        "level": "info",
        "tag": "bg.start",
        "message": "Scheduler tick ",
        "meta": {
          "source": "bg",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 258
      },
      {
        "ts": 1772056768108,
        "level": "info",
        "tag": "bg.start",
        "message": " wake alarm",
        "meta": {
          "source": "bg",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 259
      },
      {
        "ts": 1772056768831,
        "level": "info",
        "tag": "bg.error",
        "message": "Quick prebench started",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "quick",
          "modelSpec": null,
          "status": 4,
          "latencyMs": null
        },
        "seq": 260
      },
      {
        "ts": 1772056768905,
        "level": "info",
        "tag": "bg.error",
        "message": "Quick prebench finished",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "quick",
          "modelSpec": null,
          "status": 4,
          "latencyMs": null
        },
        "seq": 261
      },
      {
        "ts": 1772056768921,
        "level": "info",
        "tag": "bg.error",
        "message": "Bench started",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 262
      },
      {
        "ts": 1772056768957,
        "level": "info",
        "tag": "bg.error",
        "message": "Bench finished",
        "meta": {
          "source": "bench",
          "tabId": null,
          "requestId": null,
          "stage": "auto",
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 263
      },
      {
        "ts": 1772056768960,
        "level": "info",
        "tag": "ai.choose",
        "message": "model selected",
        "meta": {
          "source": "ai",
          "tabId": 849091790,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 264
      },
      {
        "ts": 1772060462750,
        "level": "info",
        "tag": "bg.start",
        "message": "Scheduler tick ",
        "meta": {
          "source": "bg",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 265
      },
      {
        "ts": 1772060462760,
        "level": "info",
        "tag": "bg.start",
        "message": " wake alarm",
        "meta": {
          "source": "bg",
          "tabId": null,
          "requestId": null,
          "stage": null,
          "modelSpec": null,
          "status": null,
          "latencyMs": null
        },
        "seq": 266
      }
    ]
  },
  "report": {
    "ok": true,
    "tabId": 0,
    "report": {
      "kind": "nt_test_report",
      "exportedAt": 1772060464707,
      "tabId": 0,
      "activeJobId": null,
      "lastJobId": null,
      "job": null,
      "agent": {
        "checklist": [],
        "reports": [],
        "toolExecutionTrace": [],
        "patchHistory": [],
        "recentDiffItems": []
      },
      "logs": [
        {
          "ts": 1772056677027,
          "level": "info",
          "tag": "ai.choose",
          "message": "model selected",
          "meta": {
            "source": "ai",
            "tabId": 849091790,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 67
        },
        {
          "ts": 1772056677877,
          "level": "warn",
          "tag": "ai.request",
          "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "ping",
            "modelSpec": "o4-mini:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 68
        },
        {
          "ts": 1772056678137,
          "level": "warn",
          "tag": "ai.request",
          "message": "Request aborted: ABORTED_BY_SIGNAL",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "ping",
            "modelSpec": "gpt-5:standard",
            "status": null,
            "latencyMs": null
          },
          "seq": 69
        },
        {
          "ts": 1772056678158,
          "level": "error",
          "tag": "bg.error",
          "message": "Quick bench sample failed",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "quick",
            "modelSpec": "gpt-5:standard",
            "status": null,
            "latencyMs": null
          },
          "seq": 70
        },
        {
          "ts": 1772056678159,
          "level": "info",
          "tag": "bg.error",
          "message": "Quick prebench finished",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "quick",
            "modelSpec": null,
            "status": 3,
            "latencyMs": null
          },
          "seq": 71
        },
        {
          "ts": 1772056678186,
          "level": "info",
          "tag": "ai.choose",
          "message": "model selected",
          "meta": {
            "source": "ai",
            "tabId": 849091790,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 72
        },
        {
          "ts": 1772056685686,
          "level": "info",
          "tag": "ai.response",
          "message": "ok",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "request",
            "modelSpec": "gpt-5-mini:standard",
            "status": 200,
            "latencyMs": 7486
          },
          "seq": 73
        },
        {
          "ts": 1772056685725,
          "level": "info",
          "tag": "ai.response",
          "message": "ok",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "request",
            "modelSpec": "gpt-5-mini:standard",
            "status": 200,
            "latencyMs": 8670
          },
          "seq": 74
        },
        {
          "ts": 1772056685727,
          "level": "info",
          "tag": "ai.response",
          "message": "response metrics",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": "gpt-5-mini:standard",
            "status": 200,
            "latencyMs": 7500
          },
          "seq": 75
        },
        {
          "ts": 1772056685732,
          "level": "info",
          "tag": "ai.response",
          "message": "response metrics",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": "gpt-5-mini:standard",
            "status": 200,
            "latencyMs": 8693
          },
          "seq": 76
        },
        {
          "ts": 1772056685741,
          "level": "info",
          "tag": "ai.response",
          "message": "LLM ok",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": 200,
            "latencyMs": 9166
          },
          "seq": 77
        },
        {
          "ts": 1772056685742,
          "level": "info",
          "tag": "ai.response",
          "message": "LLM ok",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": 200,
            "latencyMs": 8822
          },
          "seq": 78
        },
        {
          "ts": 1772056686698,
          "level": "warn",
          "tag": "ai.request",
          "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "ping",
            "modelSpec": "gpt-5:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 79
        },
        {
          "ts": 1772056690243,
          "level": "warn",
          "tag": "ai.request",
          "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "ping",
            "modelSpec": "o4-mini:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 80
        },
        {
          "ts": 1772056690468,
          "level": "error",
          "tag": "bg.error",
          "message": "Bench failed",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": "o4-mini:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 81
        },
        {
          "ts": 1772056690471,
          "level": "warn",
          "tag": "ai.request",
          "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "ping",
            "modelSpec": "gpt-4.1-mini:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 82
        },
        {
          "ts": 1772056690820,
          "level": "warn",
          "tag": "ai.request",
          "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "ping",
            "modelSpec": "gpt-4o-mini:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 83
        },
        {
          "ts": 1772056691056,
          "level": "error",
          "tag": "bg.error",
          "message": "Bench failed",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": "gpt-4o-mini:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 84
        },
        {
          "ts": 1772056692734,
          "level": "warn",
          "tag": "ai.request",
          "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "ping",
            "modelSpec": "gpt-5:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 85
        },
        {
          "ts": 1772056692747,
          "level": "error",
          "tag": "bg.error",
          "message": "Bench failed",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": "gpt-5:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 86
        },
        {
          "ts": 1772056692766,
          "level": "info",
          "tag": "bg.error",
          "message": "Quick prebench started",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "quick",
            "modelSpec": null,
            "status": 4,
            "latencyMs": null
          },
          "seq": 87
        },
        {
          "ts": 1772056692768,
          "level": "info",
          "tag": "bg.error",
          "message": "Quick prebench started",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "quick",
            "modelSpec": null,
            "status": 4,
            "latencyMs": null
          },
          "seq": 88
        },
        {
          "ts": 1772056692786,
          "level": "info",
          "tag": "bg.error",
          "message": "Quick prebench finished",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "quick",
            "modelSpec": null,
            "status": 4,
            "latencyMs": null
          },
          "seq": 89
        },
        {
          "ts": 1772056692788,
          "level": "info",
          "tag": "bg.error",
          "message": "Quick prebench finished",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "quick",
            "modelSpec": null,
            "status": 4,
            "latencyMs": null
          },
          "seq": 90
        },
        {
          "ts": 1772056692798,
          "level": "info",
          "tag": "bg.error",
          "message": "Bench started",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": null,
            "status": 1,
            "latencyMs": null
          },
          "seq": 91
        },
        {
          "ts": 1772056692798,
          "level": "info",
          "tag": "bg.error",
          "message": "Bench started",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": null,
            "status": 1,
            "latencyMs": null
          },
          "seq": 92
        },
        {
          "ts": 1772056692803,
          "level": "info",
          "tag": "ai.choose",
          "message": "model selected",
          "meta": {
            "source": "ai",
            "tabId": 849091790,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 93
        },
        {
          "ts": 1772056692813,
          "level": "info",
          "tag": "ai.choose",
          "message": "model selected",
          "meta": {
            "source": "ai",
            "tabId": 849091790,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 94
        },
        {
          "ts": 1772056696889,
          "level": "info",
          "tag": "ai.response",
          "message": "ok",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "request",
            "modelSpec": "gpt-5-mini:standard",
            "status": 200,
            "latencyMs": 4065
          },
          "seq": 95
        },
        {
          "ts": 1772056696928,
          "level": "info",
          "tag": "ai.response",
          "message": "response metrics",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": "gpt-5-mini:standard",
            "status": 200,
            "latencyMs": 4085
          },
          "seq": 96
        },
        {
          "ts": 1772056696936,
          "level": "warn",
          "tag": "ai.request",
          "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "ping",
            "modelSpec": "o4-mini:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 97
        },
        {
          "ts": 1772056696967,
          "level": "warn",
          "tag": "ai.request",
          "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "ping",
            "modelSpec": "gpt-4.1-mini:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 98
        },
        {
          "ts": 1772056697023,
          "level": "info",
          "tag": "ai.response",
          "message": "LLM ok",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": 200,
            "latencyMs": 4325
          },
          "seq": 99
        },
        {
          "ts": 1772056697067,
          "level": "warn",
          "tag": "ai.request",
          "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "ping",
            "modelSpec": "gpt-4.1-mini:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 100
        },
        {
          "ts": 1772056697168,
          "level": "info",
          "tag": "ai.response",
          "message": "ok",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "request",
            "modelSpec": "gpt-5-mini:standard",
            "status": 200,
            "latencyMs": 4296
          },
          "seq": 101
        },
        {
          "ts": 1772056697170,
          "level": "error",
          "tag": "bg.error",
          "message": "Bench failed",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": "gpt-4.1-mini:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 102
        },
        {
          "ts": 1772056697215,
          "level": "info",
          "tag": "ai.response",
          "message": "response metrics",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": "gpt-5-mini:standard",
            "status": 200,
            "latencyMs": 4355
          },
          "seq": 103
        },
        {
          "ts": 1772056697223,
          "level": "warn",
          "tag": "ai.request",
          "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "ping",
            "modelSpec": "o3:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 104
        },
        {
          "ts": 1772056697270,
          "level": "info",
          "tag": "ai.response",
          "message": "LLM ok",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": 200,
            "latencyMs": 4566
          },
          "seq": 105
        },
        {
          "ts": 1772056697767,
          "level": "warn",
          "tag": "ai.request",
          "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "ping",
            "modelSpec": "gpt-5:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 106
        },
        {
          "ts": 1772056698088,
          "level": "warn",
          "tag": "ai.request",
          "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "ping",
            "modelSpec": "o3:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 107
        },
        {
          "ts": 1772056700667,
          "level": "warn",
          "tag": "ai.request",
          "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "ping",
            "modelSpec": "gpt-4.1-mini:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 108
        },
        {
          "ts": 1772056701046,
          "level": "error",
          "tag": "bg.error",
          "message": "Bench failed",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": "gpt-4.1-mini:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 109
        },
        {
          "ts": 1772056701054,
          "level": "warn",
          "tag": "ai.request",
          "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "ping",
            "modelSpec": "o4-mini:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 110
        },
        {
          "ts": 1772056701188,
          "level": "error",
          "tag": "bg.error",
          "message": "Bench failed",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": "o4-mini:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 111
        },
        {
          "ts": 1772056701556,
          "level": "warn",
          "tag": "ai.request",
          "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "ping",
            "modelSpec": "o3:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 112
        },
        {
          "ts": 1772056701742,
          "level": "error",
          "tag": "bg.error",
          "message": "Bench failed",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": "o3:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 113
        },
        {
          "ts": 1772056701944,
          "level": "info",
          "tag": "bg.error",
          "message": "Bench finished",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": null,
            "status": 1,
            "latencyMs": null
          },
          "seq": 114
        },
        {
          "ts": 1772056701960,
          "level": "warn",
          "tag": "ai.request",
          "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "ping",
            "modelSpec": "o3:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 115
        },
        {
          "ts": 1772056701975,
          "level": "warn",
          "tag": "ai.request",
          "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "ping",
            "modelSpec": "gpt-5:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 116
        },
        {
          "ts": 1772056702056,
          "level": "error",
          "tag": "bg.error",
          "message": "Bench failed",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": "gpt-5:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 117
        },
        {
          "ts": 1772056702074,
          "level": "warn",
          "tag": "ai.request",
          "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "ping",
            "modelSpec": "o3:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 118
        },
        {
          "ts": 1772056702111,
          "level": "error",
          "tag": "bg.error",
          "message": "Bench failed",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": "o3:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 119
        },
        {
          "ts": 1772056702173,
          "level": "info",
          "tag": "bg.error",
          "message": "Bench finished",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": null,
            "status": 1,
            "latencyMs": null
          },
          "seq": 120
        },
        {
          "ts": 1772056702430,
          "level": "info",
          "tag": "bg.error",
          "message": "Quick prebench started",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "quick",
            "modelSpec": null,
            "status": 4,
            "latencyMs": null
          },
          "seq": 121
        },
        {
          "ts": 1772056702457,
          "level": "info",
          "tag": "bg.error",
          "message": "Quick prebench finished",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "quick",
            "modelSpec": null,
            "status": 4,
            "latencyMs": null
          },
          "seq": 122
        },
        {
          "ts": 1772056702465,
          "level": "info",
          "tag": "bg.error",
          "message": "Quick prebench started",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "quick",
            "modelSpec": null,
            "status": 4,
            "latencyMs": null
          },
          "seq": 123
        },
        {
          "ts": 1772056702494,
          "level": "info",
          "tag": "bg.error",
          "message": "Bench started",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 124
        },
        {
          "ts": 1772056702532,
          "level": "info",
          "tag": "bg.error",
          "message": "Bench finished",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 125
        },
        {
          "ts": 1772056702540,
          "level": "info",
          "tag": "ai.choose",
          "message": "model selected",
          "meta": {
            "source": "ai",
            "tabId": 849091790,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 126
        },
        {
          "ts": 1772056702566,
          "level": "info",
          "tag": "bg.error",
          "message": "Quick prebench finished",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "quick",
            "modelSpec": null,
            "status": 4,
            "latencyMs": null
          },
          "seq": 127
        },
        {
          "ts": 1772056702602,
          "level": "info",
          "tag": "bg.error",
          "message": "Bench started",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 128
        },
        {
          "ts": 1772056702605,
          "level": "info",
          "tag": "bg.error",
          "message": "Bench finished",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 129
        },
        {
          "ts": 1772056702616,
          "level": "info",
          "tag": "ai.choose",
          "message": "model selected",
          "meta": {
            "source": "ai",
            "tabId": 849091790,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 130
        },
        {
          "ts": 1772056705199,
          "level": "info",
          "tag": "ai.response",
          "message": "ok",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "request",
            "modelSpec": "gpt-5-mini:standard",
            "status": 200,
            "latencyMs": 2601
          },
          "seq": 131
        },
        {
          "ts": 1772056705330,
          "level": "warn",
          "tag": "ai.request",
          "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "ping",
            "modelSpec": "gpt-5:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 132
        },
        {
          "ts": 1772056705338,
          "level": "info",
          "tag": "ai.response",
          "message": "response metrics",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": "gpt-5-mini:standard",
            "status": 200,
            "latencyMs": 2665
          },
          "seq": 133
        },
        {
          "ts": 1772056705360,
          "level": "warn",
          "tag": "ai.request",
          "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "ping",
            "modelSpec": "gpt-4.1-mini:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 134
        },
        {
          "ts": 1772056705364,
          "level": "info",
          "tag": "ai.response",
          "message": "LLM ok",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": 200,
            "latencyMs": 3305
          },
          "seq": 135
        },
        {
          "ts": 1772056706087,
          "level": "info",
          "tag": "ai.response",
          "message": "ok",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "request",
            "modelSpec": "gpt-5-mini:standard",
            "status": 200,
            "latencyMs": 3457
          },
          "seq": 136
        },
        {
          "ts": 1772056706233,
          "level": "info",
          "tag": "ai.response",
          "message": "response metrics",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": "gpt-5-mini:standard",
            "status": 200,
            "latencyMs": 3475
          },
          "seq": 137
        },
        {
          "ts": 1772056706266,
          "level": "warn",
          "tag": "ai.request",
          "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "ping",
            "modelSpec": "o3:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 138
        },
        {
          "ts": 1772056706321,
          "level": "info",
          "tag": "ai.response",
          "message": "LLM ok",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": 200,
            "latencyMs": 4148
          },
          "seq": 139
        },
        {
          "ts": 1772056706336,
          "level": "warn",
          "tag": "ai.request",
          "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "ping",
            "modelSpec": "o3:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 140
        },
        {
          "ts": 1772056706425,
          "level": "error",
          "tag": "bg.error",
          "message": "Bench failed",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": "o3:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 141
        },
        {
          "ts": 1772056706625,
          "level": "info",
          "tag": "bg.error",
          "message": "Bench finished",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": null,
            "status": 2,
            "latencyMs": null
          },
          "seq": 142
        },
        {
          "ts": 1772056708511,
          "level": "warn",
          "tag": "ai.request",
          "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "ping",
            "modelSpec": "gpt-5:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 143
        },
        {
          "ts": 1772056708845,
          "level": "error",
          "tag": "bg.error",
          "message": "Bench failed",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": "gpt-5:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 144
        },
        {
          "ts": 1772056709399,
          "level": "warn",
          "tag": "ai.request",
          "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "ping",
            "modelSpec": "gpt-4.1-mini:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 145
        },
        {
          "ts": 1772056709715,
          "level": "error",
          "tag": "bg.error",
          "message": "Bench failed",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": "gpt-4.1-mini:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 146
        },
        {
          "ts": 1772056709875,
          "level": "warn",
          "tag": "ai.request",
          "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "ping",
            "modelSpec": "o3:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 147
        },
        {
          "ts": 1772056709968,
          "level": "error",
          "tag": "bg.error",
          "message": "Bench failed",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": "o3:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 148
        },
        {
          "ts": 1772056710097,
          "level": "info",
          "tag": "bg.error",
          "message": "Bench finished",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": null,
            "status": 3,
            "latencyMs": null
          },
          "seq": 149
        },
        {
          "ts": 1772056710905,
          "level": "info",
          "tag": "bg.error",
          "message": "Quick prebench started",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "quick",
            "modelSpec": null,
            "status": 4,
            "latencyMs": null
          },
          "seq": 150
        },
        {
          "ts": 1772056711018,
          "level": "info",
          "tag": "bg.error",
          "message": "Quick prebench finished",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "quick",
            "modelSpec": null,
            "status": 4,
            "latencyMs": null
          },
          "seq": 151
        },
        {
          "ts": 1772056711087,
          "level": "info",
          "tag": "bg.error",
          "message": "Bench started",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 152
        },
        {
          "ts": 1772056711091,
          "level": "info",
          "tag": "ai.choose",
          "message": "model selected",
          "meta": {
            "source": "ai",
            "tabId": 849091790,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 153
        },
        {
          "ts": 1772056711111,
          "level": "info",
          "tag": "bg.error",
          "message": "Bench finished",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 154
        },
        {
          "ts": 1772056711187,
          "level": "warn",
          "tag": "ai.request",
          "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "ping",
            "modelSpec": "gpt-4.1-mini:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 155
        },
        {
          "ts": 1772056711197,
          "level": "info",
          "tag": "bg.error",
          "message": "Quick prebench started",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "quick",
            "modelSpec": null,
            "status": 4,
            "latencyMs": null
          },
          "seq": 156
        },
        {
          "ts": 1772056711224,
          "level": "info",
          "tag": "bg.error",
          "message": "Quick prebench finished",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "quick",
            "modelSpec": null,
            "status": 4,
            "latencyMs": null
          },
          "seq": 157
        },
        {
          "ts": 1772056711397,
          "level": "info",
          "tag": "bg.error",
          "message": "Bench started",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 158
        },
        {
          "ts": 1772056711400,
          "level": "info",
          "tag": "ai.choose",
          "message": "model selected",
          "meta": {
            "source": "ai",
            "tabId": 849091790,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 159
        },
        {
          "ts": 1772056711452,
          "level": "info",
          "tag": "bg.error",
          "message": "Bench finished",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 160
        },
        {
          "ts": 1772056714917,
          "level": "info",
          "tag": "ai.response",
          "message": "ok",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "request",
            "modelSpec": "gpt-5-mini:standard",
            "status": 200,
            "latencyMs": 3429
          },
          "seq": 161
        },
        {
          "ts": 1772056714962,
          "level": "info",
          "tag": "ai.response",
          "message": "response metrics",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": "gpt-5-mini:standard",
            "status": 200,
            "latencyMs": 3516
          },
          "seq": 162
        },
        {
          "ts": 1772056714964,
          "level": "info",
          "tag": "ai.response",
          "message": "ok",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "request",
            "modelSpec": "gpt-5-mini:standard",
            "status": 200,
            "latencyMs": 3840
          },
          "seq": 163
        },
        {
          "ts": 1772056714978,
          "level": "info",
          "tag": "ai.response",
          "message": "response metrics",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": "gpt-5-mini:standard",
            "status": 200,
            "latencyMs": 3872
          },
          "seq": 164
        },
        {
          "ts": 1772056714981,
          "level": "warn",
          "tag": "ai.request",
          "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "ping",
            "modelSpec": "o3:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 165
        },
        {
          "ts": 1772056714985,
          "level": "info",
          "tag": "ai.response",
          "message": "LLM ok",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": 200,
            "latencyMs": 3967
          },
          "seq": 166
        },
        {
          "ts": 1772056715003,
          "level": "info",
          "tag": "ai.response",
          "message": "LLM ok",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": 200,
            "latencyMs": 4588
          },
          "seq": 167
        },
        {
          "ts": 1772056715903,
          "level": "warn",
          "tag": "ai.request",
          "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "ping",
            "modelSpec": "gpt-4.1-mini:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 168
        },
        {
          "ts": 1772056716013,
          "level": "error",
          "tag": "bg.error",
          "message": "Bench failed",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": "gpt-4.1-mini:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 169
        },
        {
          "ts": 1772056717840,
          "level": "warn",
          "tag": "ai.request",
          "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "ping",
            "modelSpec": "o3:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 170
        },
        {
          "ts": 1772056718121,
          "level": "error",
          "tag": "bg.error",
          "message": "Bench failed",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": "o3:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 171
        },
        {
          "ts": 1772056718403,
          "level": "info",
          "tag": "bg.error",
          "message": "Bench finished",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": null,
            "status": 5,
            "latencyMs": null
          },
          "seq": 172
        },
        {
          "ts": 1772056719350,
          "level": "warn",
          "tag": "ai.request",
          "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "ping",
            "modelSpec": "o3:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 173
        },
        {
          "ts": 1772056719666,
          "level": "info",
          "tag": "bg.error",
          "message": "Quick prebench started",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "quick",
            "modelSpec": null,
            "status": 4,
            "latencyMs": null
          },
          "seq": 174
        },
        {
          "ts": 1772056719677,
          "level": "info",
          "tag": "bg.error",
          "message": "Quick prebench started",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "quick",
            "modelSpec": null,
            "status": 4,
            "latencyMs": null
          },
          "seq": 175
        },
        {
          "ts": 1772056719688,
          "level": "info",
          "tag": "bg.error",
          "message": "Quick prebench finished",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "quick",
            "modelSpec": null,
            "status": 4,
            "latencyMs": null
          },
          "seq": 176
        },
        {
          "ts": 1772056719716,
          "level": "info",
          "tag": "bg.error",
          "message": "Bench started",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 177
        },
        {
          "ts": 1772056719740,
          "level": "info",
          "tag": "bg.error",
          "message": "Quick prebench finished",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "quick",
            "modelSpec": null,
            "status": 4,
            "latencyMs": null
          },
          "seq": 178
        },
        {
          "ts": 1772056719742,
          "level": "info",
          "tag": "bg.error",
          "message": "Bench finished",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 179
        },
        {
          "ts": 1772056719744,
          "level": "info",
          "tag": "bg.error",
          "message": "Bench started",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 180
        },
        {
          "ts": 1772056719747,
          "level": "info",
          "tag": "ai.choose",
          "message": "model selected",
          "meta": {
            "source": "ai",
            "tabId": 849091790,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 181
        },
        {
          "ts": 1772056719791,
          "level": "info",
          "tag": "bg.error",
          "message": "Bench finished",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 182
        },
        {
          "ts": 1772056719812,
          "level": "info",
          "tag": "ai.choose",
          "message": "model selected",
          "meta": {
            "source": "ai",
            "tabId": 849091790,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 183
        },
        {
          "ts": 1772056725682,
          "level": "info",
          "tag": "ai.response",
          "message": "ok",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "request",
            "modelSpec": "gpt-5-mini:standard",
            "status": 200,
            "latencyMs": 5870
          },
          "seq": 184
        },
        {
          "ts": 1772056725751,
          "level": "warn",
          "tag": "ai.request",
          "message": "Invalid 'max_output_tokens': integer below minimum value. Expected a value >= 16, but got 4 instead.",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "ping",
            "modelSpec": "o3:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 185
        },
        {
          "ts": 1772056725753,
          "level": "info",
          "tag": "ai.response",
          "message": "response metrics",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": "gpt-5-mini:standard",
            "status": 200,
            "latencyMs": 5934
          },
          "seq": 186
        },
        {
          "ts": 1772056725755,
          "level": "info",
          "tag": "ai.response",
          "message": "ok",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "request",
            "modelSpec": "gpt-5-mini:standard",
            "status": 200,
            "latencyMs": 5929
          },
          "seq": 187
        },
        {
          "ts": 1772056725791,
          "level": "info",
          "tag": "ai.response",
          "message": "response metrics",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": "gpt-5-mini:standard",
            "status": 200,
            "latencyMs": 5940
          },
          "seq": 188
        },
        {
          "ts": 1772056725815,
          "level": "error",
          "tag": "bg.error",
          "message": "Bench failed",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": "o3:standard",
            "status": 400,
            "latencyMs": null
          },
          "seq": 189
        },
        {
          "ts": 1772056725819,
          "level": "info",
          "tag": "ai.response",
          "message": "LLM ok",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": 200,
            "latencyMs": 6347
          },
          "seq": 190
        },
        {
          "ts": 1772056725850,
          "level": "info",
          "tag": "ai.response",
          "message": "LLM ok",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": 200,
            "latencyMs": 6375
          },
          "seq": 191
        },
        {
          "ts": 1772056725879,
          "level": "info",
          "tag": "bg.error",
          "message": "Bench finished",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": null,
            "status": 6,
            "latencyMs": null
          },
          "seq": 192
        },
        {
          "ts": 1772056728190,
          "level": "info",
          "tag": "bg.error",
          "message": "Quick prebench started",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "quick",
            "modelSpec": null,
            "status": 4,
            "latencyMs": null
          },
          "seq": 193
        },
        {
          "ts": 1772056728193,
          "level": "info",
          "tag": "bg.error",
          "message": "Quick prebench started",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "quick",
            "modelSpec": null,
            "status": 4,
            "latencyMs": null
          },
          "seq": 194
        },
        {
          "ts": 1772056728203,
          "level": "info",
          "tag": "bg.error",
          "message": "Quick prebench finished",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "quick",
            "modelSpec": null,
            "status": 4,
            "latencyMs": null
          },
          "seq": 195
        },
        {
          "ts": 1772056728212,
          "level": "info",
          "tag": "bg.error",
          "message": "Quick prebench finished",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "quick",
            "modelSpec": null,
            "status": 4,
            "latencyMs": null
          },
          "seq": 196
        },
        {
          "ts": 1772056728214,
          "level": "info",
          "tag": "bg.error",
          "message": "Bench started",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 197
        },
        {
          "ts": 1772056728214,
          "level": "info",
          "tag": "bg.error",
          "message": "Bench started",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 198
        },
        {
          "ts": 1772056728222,
          "level": "info",
          "tag": "ai.choose",
          "message": "model selected",
          "meta": {
            "source": "ai",
            "tabId": 849091790,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 199
        },
        {
          "ts": 1772056728224,
          "level": "info",
          "tag": "bg.error",
          "message": "Bench finished",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 200
        },
        {
          "ts": 1772056728224,
          "level": "info",
          "tag": "bg.error",
          "message": "Bench finished",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 201
        },
        {
          "ts": 1772056728246,
          "level": "info",
          "tag": "ai.choose",
          "message": "model selected",
          "meta": {
            "source": "ai",
            "tabId": 849091790,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 202
        },
        {
          "ts": 1772056730534,
          "level": "info",
          "tag": "ai.response",
          "message": "ok",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "request",
            "modelSpec": "gpt-5:standard",
            "status": 200,
            "latencyMs": 2285
          },
          "seq": 203
        },
        {
          "ts": 1772056730536,
          "level": "info",
          "tag": "ai.response",
          "message": "ok",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "request",
            "modelSpec": "gpt-5:standard",
            "status": 200,
            "latencyMs": 2279
          },
          "seq": 204
        },
        {
          "ts": 1772056730545,
          "level": "info",
          "tag": "ai.response",
          "message": "response metrics",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": "gpt-5:standard",
            "status": 200,
            "latencyMs": 2311
          },
          "seq": 205
        },
        {
          "ts": 1772056730547,
          "level": "info",
          "tag": "ai.response",
          "message": "response metrics",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": "gpt-5:standard",
            "status": 200,
            "latencyMs": 2289
          },
          "seq": 206
        },
        {
          "ts": 1772056730556,
          "level": "info",
          "tag": "ai.response",
          "message": "LLM ok",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": 200,
            "latencyMs": 2377
          },
          "seq": 207
        },
        {
          "ts": 1772056730558,
          "level": "info",
          "tag": "ai.response",
          "message": "LLM ok",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": 200,
            "latencyMs": 2377
          },
          "seq": 208
        },
        {
          "ts": 1772056736742,
          "level": "info",
          "tag": "bg.start",
          "message": " wake alarm",
          "meta": {
            "source": "bg",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 209
        },
        {
          "ts": 1772056737880,
          "level": "info",
          "tag": "bg.start",
          "message": "Scheduler tick ",
          "meta": {
            "source": "bg",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 210
        },
        {
          "ts": 1772056737888,
          "level": "info",
          "tag": "bg.start",
          "message": " wake alarm",
          "meta": {
            "source": "bg",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 211
        },
        {
          "ts": 1772056739343,
          "level": "info",
          "tag": "bg.start",
          "message": " wake alarm",
          "meta": {
            "source": "bg",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 212
        },
        {
          "ts": 1772056739606,
          "level": "info",
          "tag": "bg.start",
          "message": "Scheduler tick ",
          "meta": {
            "source": "bg",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 213
        },
        {
          "ts": 1772056740056,
          "level": "info",
          "tag": "bg.start",
          "message": " wake alarm",
          "meta": {
            "source": "bg",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 214
        },
        {
          "ts": 1772056740439,
          "level": "info",
          "tag": "bg.start",
          "message": "Scheduler tick ",
          "meta": {
            "source": "bg",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 215
        },
        {
          "ts": 1772056742079,
          "level": "info",
          "tag": "bg.error",
          "message": "Quick prebench started",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "quick",
            "modelSpec": null,
            "status": 4,
            "latencyMs": null
          },
          "seq": 216
        },
        {
          "ts": 1772056742091,
          "level": "info",
          "tag": "bg.start",
          "message": "Scheduler tick ",
          "meta": {
            "source": "bg",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 217
        },
        {
          "ts": 1772056742095,
          "level": "info",
          "tag": "bg.start",
          "message": " wake alarm",
          "meta": {
            "source": "bg",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 218
        },
        {
          "ts": 1772056742104,
          "level": "info",
          "tag": "bg.error",
          "message": "Bench started",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 219
        },
        {
          "ts": 1772056742104,
          "level": "info",
          "tag": "bg.error",
          "message": "Quick prebench finished",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "quick",
            "modelSpec": null,
            "status": 4,
            "latencyMs": null
          },
          "seq": 220
        },
        {
          "ts": 1772056742115,
          "level": "info",
          "tag": "bg.error",
          "message": "Bench finished",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 221
        },
        {
          "ts": 1772056742135,
          "level": "info",
          "tag": "ai.choose",
          "message": "model selected",
          "meta": {
            "source": "ai",
            "tabId": 849091790,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 222
        },
        {
          "ts": 1772056744386,
          "level": "info",
          "tag": "bg.start",
          "message": "Scheduler tick ",
          "meta": {
            "source": "bg",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 223
        },
        {
          "ts": 1772056744391,
          "level": "info",
          "tag": "bg.start",
          "message": " wake alarm",
          "meta": {
            "source": "bg",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 224
        },
        {
          "ts": 1772056745905,
          "level": "info",
          "tag": "ai.response",
          "message": "ok",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "request",
            "modelSpec": "gpt-5-mini:standard",
            "status": 200,
            "latencyMs": 3720
          },
          "seq": 225
        },
        {
          "ts": 1772056745984,
          "level": "info",
          "tag": "ai.response",
          "message": "response metrics",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": "gpt-5-mini:standard",
            "status": 200,
            "latencyMs": 3769
          },
          "seq": 226
        },
        {
          "ts": 1772056745995,
          "level": "info",
          "tag": "ai.response",
          "message": "LLM ok",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": 200,
            "latencyMs": 4233
          },
          "seq": 227
        },
        {
          "ts": 1772056747582,
          "level": "info",
          "tag": "bg.start",
          "message": "Scheduler tick ",
          "meta": {
            "source": "bg",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 228
        },
        {
          "ts": 1772056747589,
          "level": "info",
          "tag": "bg.start",
          "message": " wake alarm",
          "meta": {
            "source": "bg",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 229
        },
        {
          "ts": 1772056750680,
          "level": "info",
          "tag": "bg.start",
          "message": "Scheduler tick ",
          "meta": {
            "source": "bg",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 230
        },
        {
          "ts": 1772056750688,
          "level": "info",
          "tag": "bg.start",
          "message": " wake alarm",
          "meta": {
            "source": "bg",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 231
        },
        {
          "ts": 1772056751847,
          "level": "info",
          "tag": "bg.error",
          "message": "Quick prebench started",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "quick",
            "modelSpec": null,
            "status": 4,
            "latencyMs": null
          },
          "seq": 232
        },
        {
          "ts": 1772056751944,
          "level": "info",
          "tag": "bg.error",
          "message": "Quick prebench finished",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "quick",
            "modelSpec": null,
            "status": 4,
            "latencyMs": null
          },
          "seq": 233
        },
        {
          "ts": 1772056751958,
          "level": "info",
          "tag": "bg.error",
          "message": "Bench started",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 234
        },
        {
          "ts": 1772056751962,
          "level": "info",
          "tag": "bg.error",
          "message": "Bench finished",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 235
        },
        {
          "ts": 1772056751976,
          "level": "info",
          "tag": "ai.choose",
          "message": "model selected",
          "meta": {
            "source": "ai",
            "tabId": 849091790,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 236
        },
        {
          "ts": 1772056752712,
          "level": "info",
          "tag": "bg.start",
          "message": "Scheduler tick ",
          "meta": {
            "source": "bg",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 237
        },
        {
          "ts": 1772056752717,
          "level": "info",
          "tag": "bg.start",
          "message": " wake alarm",
          "meta": {
            "source": "bg",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 238
        },
        {
          "ts": 1772056754799,
          "level": "info",
          "tag": "ai.response",
          "message": "ok",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "request",
            "modelSpec": "gpt-5-mini:standard",
            "status": 200,
            "latencyMs": 2809
          },
          "seq": 239
        },
        {
          "ts": 1772056754846,
          "level": "info",
          "tag": "ai.response",
          "message": "response metrics",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": "gpt-5-mini:standard",
            "status": 200,
            "latencyMs": 2823
          },
          "seq": 240
        },
        {
          "ts": 1772056754919,
          "level": "info",
          "tag": "ai.response",
          "message": "LLM ok",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": 200,
            "latencyMs": 3555
          },
          "seq": 241
        },
        {
          "ts": 1772056755437,
          "level": "info",
          "tag": "bg.start",
          "message": "Scheduler tick ",
          "meta": {
            "source": "bg",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 242
        },
        {
          "ts": 1772056755448,
          "level": "info",
          "tag": "bg.start",
          "message": " wake alarm",
          "meta": {
            "source": "bg",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 243
        },
        {
          "ts": 1772056761002,
          "level": "info",
          "tag": "bg.start",
          "message": "Scheduler tick ",
          "meta": {
            "source": "bg",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 244
        },
        {
          "ts": 1772056761006,
          "level": "info",
          "tag": "bg.start",
          "message": " wake alarm",
          "meta": {
            "source": "bg",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 245
        },
        {
          "ts": 1772056763622,
          "level": "info",
          "tag": "bg.error",
          "message": "Quick prebench started",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "quick",
            "modelSpec": null,
            "status": 4,
            "latencyMs": null
          },
          "seq": 246
        },
        {
          "ts": 1772056763635,
          "level": "info",
          "tag": "bg.error",
          "message": "Quick prebench finished",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "quick",
            "modelSpec": null,
            "status": 4,
            "latencyMs": null
          },
          "seq": 247
        },
        {
          "ts": 1772056763647,
          "level": "info",
          "tag": "bg.start",
          "message": "Scheduler tick ",
          "meta": {
            "source": "bg",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 248
        },
        {
          "ts": 1772056763650,
          "level": "info",
          "tag": "bg.error",
          "message": "Bench started",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 249
        },
        {
          "ts": 1772056763652,
          "level": "info",
          "tag": "bg.start",
          "message": " wake alarm",
          "meta": {
            "source": "bg",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 250
        },
        {
          "ts": 1772056763661,
          "level": "info",
          "tag": "bg.error",
          "message": "Bench finished",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 251
        },
        {
          "ts": 1772056763670,
          "level": "info",
          "tag": "ai.choose",
          "message": "model selected",
          "meta": {
            "source": "ai",
            "tabId": 849091790,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 252
        },
        {
          "ts": 1772056765647,
          "level": "info",
          "tag": "bg.start",
          "message": "Scheduler tick ",
          "meta": {
            "source": "bg",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 253
        },
        {
          "ts": 1772056765651,
          "level": "info",
          "tag": "bg.start",
          "message": " wake alarm",
          "meta": {
            "source": "bg",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 254
        },
        {
          "ts": 1772056767075,
          "level": "info",
          "tag": "ai.response",
          "message": "ok",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": "request",
            "modelSpec": "gpt-5-mini:standard",
            "status": 200,
            "latencyMs": 3383
          },
          "seq": 255
        },
        {
          "ts": 1772056767086,
          "level": "info",
          "tag": "ai.response",
          "message": "response metrics",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": "gpt-5-mini:standard",
            "status": 200,
            "latencyMs": 3404
          },
          "seq": 256
        },
        {
          "ts": 1772056767098,
          "level": "info",
          "tag": "ai.response",
          "message": "LLM ok",
          "meta": {
            "source": "ai",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": 200,
            "latencyMs": 3726
          },
          "seq": 257
        },
        {
          "ts": 1772056768104,
          "level": "info",
          "tag": "bg.start",
          "message": "Scheduler tick ",
          "meta": {
            "source": "bg",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 258
        },
        {
          "ts": 1772056768108,
          "level": "info",
          "tag": "bg.start",
          "message": " wake alarm",
          "meta": {
            "source": "bg",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 259
        },
        {
          "ts": 1772056768831,
          "level": "info",
          "tag": "bg.error",
          "message": "Quick prebench started",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "quick",
            "modelSpec": null,
            "status": 4,
            "latencyMs": null
          },
          "seq": 260
        },
        {
          "ts": 1772056768905,
          "level": "info",
          "tag": "bg.error",
          "message": "Quick prebench finished",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "quick",
            "modelSpec": null,
            "status": 4,
            "latencyMs": null
          },
          "seq": 261
        },
        {
          "ts": 1772056768921,
          "level": "info",
          "tag": "bg.error",
          "message": "Bench started",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 262
        },
        {
          "ts": 1772056768957,
          "level": "info",
          "tag": "bg.error",
          "message": "Bench finished",
          "meta": {
            "source": "bench",
            "tabId": null,
            "requestId": null,
            "stage": "auto",
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 263
        },
        {
          "ts": 1772056768960,
          "level": "info",
          "tag": "ai.choose",
          "message": "model selected",
          "meta": {
            "source": "ai",
            "tabId": 849091790,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 264
        },
        {
          "ts": 1772060462750,
          "level": "info",
          "tag": "bg.start",
          "message": "Scheduler tick ",
          "meta": {
            "source": "bg",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 265
        },
        {
          "ts": 1772060462760,
          "level": "info",
          "tag": "bg.start",
          "message": " wake alarm",
          "meta": {
            "source": "bg",
            "tabId": null,
            "requestId": null,
            "stage": null,
            "modelSpec": null,
            "status": null,
            "latencyMs": null
          },
          "seq": 266
        }
      ]
    }
  },
  "summaryState": {
    "hasJobsRoot": true,
    "statusByTabKeys": [
      "849091790"
    ]
  },
  "mockStats": {
    "totalRequests": 0,
    "responsesRequests": 0,
    "streamRequests": 0,
    "nonStreamRequests": 0,
    "toolRequests": 0,
    "status429": 0,
    "status5xx": 0,
    "streamAborts": 0
  },
  "mockRecentRequests": []
}